<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning a Robotic Hand Imitator by Watching Humans on Youtube">
  <meta name="keywords" content="Teleoperation, Imitation Learning, Robotics, Dexterous Manipuation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Robotic Telekinesis: Learning a Robotic Hand Imitator by Watching Humans on Youtube</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!--<link rel="icon" href="./favicon.ico?"> -->

  <!-- <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Deepak Pathak" /> -->
  <!-- <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" /> -->
  <meta name="twitter:site" content="@pathak2206" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:image" content="https://energy-locomotion.github.io/static/images/preview.jpg" />
  <meta name="twitter:player" content="https://www.youtube.com/embed/OQN5W2IAb9k" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Robotic Telekinesis:</h1><h2 class = "title is-34 publication-title">Learning a Robotic Hand Imitator by Watching Humans on Youtube</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <!-- <a>Aravind Sivakumar</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a>â€ªKenneth Shaw</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a><sup>1</sup>
              <br /><sup>1</sup>Carnegie Mellon University
              <span class="brmod">ArXiv 2022</span> -->
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./resources/CoRL-Energy-Locomotion.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#method_video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
    <div class="columns is-centered">
      <div class="column is-two-thirds">
        <div id="method_video" class="columns is-centered has-text-centered">
            <div class="publication-video">
              <iframe src="https://drive.google.com/file/d/1zYMclXRx-ZU7ajVb6hNqdCNlmQtDP0En/preview"
                      width="1080" height="480" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
        </div>
        <h2 class="subtitle has-text-centered">

        </h2>
      </div>
    </div>
</section>


<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          We build a system that enables a human to control a robot hand and arm, simply by demonstrating motions with their own hand. The robot observes the human operator via a single RGB camera and imitates their actions \textbf{in real-time}. Human hands and robot hands differ in shape, size, and joint structure, and performing this translation from a single uncalibrated camera is a highly underconstrained problem. Moreover, the retargeted trajectories must effectively execute tasks on a physical robot, which requires them to be temporally smooth and free of self-collisions. Our key insight is that while paired human-robot correspondence data is expensive to collect, the internet contains a massive corpus of rich and diverse human hand videos. We leverage this data in order to train a system that understands human hands, and retargets a human video stream into a robot hand-arm trajectory that is smooth, swift, safe, and semantically similar to the guiding demonstration. We demonstrate that it enables previously untrained people to teleoperate a robot on various dexterous manipulation tasks. We hope this work makes robot teaching more accessible, and that in the future, our system can be used to aid robots that learn to act autonomously in the real world.
          </p>
        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->

  <!-- Paper video. -->
  <!--/ Paper video. -->
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Tasks</h2>
        <tr>
          <td>
            <br>
            <div class="columns is-centered has-text-centered">
              <img src="./static/images/Tasks_Expert.png" style="border: 1px solid #bbb; border-radius: 10px; width: 80%;"></img>
            </div>
          </td>
        </tr>
        <div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              The <b>expert operator completes task </b> with the robot.  These tasks from left to right, from the first row are Pickup Dice Toy, Pickup Dinosaur   Doll, Box Rotation, Scissor Pickup, Cup Stack.  On the second row, two cup stacking, pouring cubes onto plate, cup into plate, open drawer and open drawer and pickup cup.
            </p>
          </div>
        </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Method</h2>

        <tr>
          <td>
            <br>
            <div class="columns is-centered has-text-centered">
              <img src="./resources/crop_method.png" style="border: 1px solid #bbb; border-radius: 10px; width: 80%;"></img>
            </div>
          </td>
        </tr>
        <div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              <b>Our system:</b> Consists of an xArm6 robot arm, a 16-DoF Allegro robot hand and a single RGB camera that captures a stream of images of the human operator.  The camera can be placed anywhere as long as the operator is within the camera's field of view.  Each captured image at 30hz is retargeted into a pair of robot commands (one for the Allegro hand and one for the xArm) which place the robot hand and arm in poses that match the hand-arm poses of the human operator.  This capture-retarget-command loop allows the operator to guide the robot to complete tasks while watching the robot mimic them in real-time.  The figure illustrates operators using the system to solve a pair of grasping tasks.
            </p>
          </div>
        </div>
      </div>
    </div>


    <br><br>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Human Subject Study
        </br>
        <br>
            <img src="./resources/table.png" style="border: 1px solid #bbb; border-radius: 10px; width: 90%;"></img>
      </div>
    </div>
    <div class="is-vcentered interpolation-panel">
      <div class="content has-text-centered">
        <p>
          <b>Success rate and completion time of a trained operator completing a variety of tasks using two methods.</b>  Our system outperforms the baseline in 7 out of 10 tasks and is either equal or similar in performance on the other three tasks.  In practice, users found our system to be more fluid and easier to control.  *Dexpilot-Single is reimplementation of Dexpilot with one camera instead of four and using a gradient descent solver as original code was not released.
        </p>
      </div>
    </div>
    </br>
    <div class="columns is-centered">
      <div class="column is-full-width">
        </br>
        <br>
            <img src="./resources/graphs.PNG" style="border: 1px solid #bbb; border-radius: 10px; width: 90%;"></img>
      </div>
    </div>
    <div class="is-vcentered interpolation-panel">
      <div class="content has-text-centered">
        <p>
          <b>Ten rookie operators were asked to complete tasks:</b> Picking up a plush dice, opening a plastic drawer, and placing a cup onto a plate. After seven tries at each task, the mean and standard deviation of their completion times were recorded per task.
        </p>
      </div>
    </div>


    <br><br>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Test Time Optimization vs Learned Neural Network Retargeting
        </br>
        <br>
            <img src="./resources/energy_function-crop.png" style="border: 1px solid #bbb; border-radius: 10px; width: 40%;"></img>
      </div>
    </div>
    <div class="is-vcentered interpolation-panel">
      <div class="content has-text-centered">
        <p>
          <b>Human-to-robot Translations:</b>  The inputs and outputs of our hand retargeting network.  Each of the pairs depicts a human hand pose, and the retargeted Allegro hand pose.
        </p>
      </div>
    </div>

    <br><br>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Test Time Optimization vs Learned Neural Network Retargeting
        </br>
        <br>
            <img src="./static/images/self_collision.png" style="border: 1px solid #bbb; border-radius: 10px; width: 40%;"></img>
      </div>
    </div>
    <div class="is-vcentered interpolation-panel">
      <div class="content has-text-centered">
        <p>
        We compare a vanilla hand retargeting network versus ours with a self-collision loss.  The red boxes highlight instances where the vanilla network outputs Allegro hand poses that result in self-collision.  The green boxes depict the predictions of the network trained with self-collision loss.  These robot hand poses maintain functional similarity to the human's hand pose, but avoid self-collision.
        </p>
      </div>
    </div>


    <br><br>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="text-align: center;">Experiment Videos from Inexperienced Operators</h2>
        <tr>
          <td>
            <br>
              <div class="columns is-centered has-text-centered v-divider">
                <video allow="autoplay; encrypted-media" autoplay loop muted playsinline  allowfullscreen src="https://drive.google.com/file/d/1odE6Zo8pcasP4M5XCczsef3vUpfxtgnZ/preview" style="border: 1px solid #bbb; border-radius: 10px; width: 50%;"></video>
                &nbsp;
                <video allow="autoplay; encrypted-media" autoplay loop muted playsinline  allowfullscreen src="https://drive.google.com/file/d/1q4NQ8IbyyPoGmZkN-CQ6_gyd6DUAhuhw/preview" style="border: 1px solid #bbb; border-radius: 10px; width: 50%;"></video>
              </div>
              <br />
              <div class="columns is-centered has-text-centered v-divider">
                <video allow="autoplay; encrypted-media" autoplay loop muted playsinline  allowfullscreen src="https://drive.google.com/file/d/1h_AGMp5aAI-v9oNVpUuDquKS0DJpVtbN/preview" style="border: 1px solid #bbb; border-radius: 10px; width: 50%;"></video>
                &nbsp;
                <video allow="autoplay; encrypted-media" autoplay loop muted playsinline allowfullscreen src="https://drive.google.com/file/d/1DOq2vW0HrsZxxDeSU7ImvuFffuEwhxyt/preview" style="border: 1px solid #bbb; border-radius: 10px; width: 50%;"></video>
              </div>
          </td>
        </tr>
        <div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              Collage of various inexperienced operators completing tasks with Telekinesis.
            </p>
          </div>
        </div>
      </div>
    </div>

    <br><br>
  </div>
</section>





<!--<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="titile">BibTeX</h2>
    <pre><code>@inproceedings{as_telekinesis,
  author    = {Sivakumar, Aravind and Shaw, Kenneth and Pathak, Deepak},
  title     = {Robotic Telekinesis: Learning a Robotic Hand Imitator by Watching Humans on Youtube},
  journal   = {RSS (Robotics: Science and Systems)},
  year      = {2022},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a href="./resources/CoRL-Energy-Locomotion.pdf" class="large-font bottom_buttons">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- <a class="large-font bottom_buttons" disabled>
        <i class="fab fa-github"></i>
      </a> -->
      <br />
      <p>Page template borrowed from <a href="https://nerfies.github.io"><span class="dnerf">Nerfies</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
